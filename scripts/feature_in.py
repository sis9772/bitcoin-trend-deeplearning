import scipy.io
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split

# .mat íŒŒì¼ ë¡œë“œ
data = scipy.io.loadmat('btc_features.mat')
X = data['X']  # (N, T, F)
y = data['y'].flatten()

# ì‹œí€€ìŠ¤ í‰ê·  pooling
X_avg = X.mean(axis=1)  # (N, F)

# train-test split
X_train, X_test, y_train, y_test = train_test_split(X_avg, y, test_size=0.2, random_state=42)

# ëœë¤í¬ë ˆìŠ¤íŠ¸ë¡œ ì¤‘ìš”ë„ í•™ìŠµ
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# ì¤‘ìš”ë„ ì¶œë ¥
importances = clf.feature_importances_
sorted_idx = np.argsort(importances)[::-1]

print("ğŸ“Š ìƒìœ„ ì¤‘ìš” í”¼ì²˜:")
for i in sorted_idx[:10]:
    print(f"  Feature {i} - Importance: {importances[i]:.4f}")

# ì¤‘ìš”ë„ ê¸°ë°˜ ì‹œê°í™”
import matplotlib.pyplot as plt
plt.figure(figsize=(10,5))
plt.bar(range(len(importances)), importances)
plt.title("ğŸ“Œ Feature Importances")
plt.xlabel("Feature Index")
plt.ylabel("Importance")
plt.show()